{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy, SciPy, Scikit-learn\n",
    "They are three fundamental libraries in the Python ecosystem, especially for data science, machine learning, and scientific computing. They are closely related and often used together in various workflows. Here's how they are connected:\n",
    "\n",
    "1. NumPy\n",
    "Core Library: NumPy is the foundational package for numerical computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "Core Data Structures: Scikit-learn heavily relies on NumPy arrays (especially the ndarray data structure) as the standard format for input data. When you pass data into scikit-learn algorithms, it is usually in the form of a NumPy array.\n",
    "Numerical Operations: Many of the computations within scikit-learn, such as linear algebra operations, are performed using NumPy's efficient, low-level implementations.\n",
    "2. SciPy\n",
    "Advanced Scientific Functions: SciPy builds on NumPy and provides additional functionality for scientific and technical computing. It includes modules for optimization, integration, interpolation, eigenvalue problems, algebraic equations, and others.\n",
    "Scikit-learn Dependency: Scikit-learn utilizes functions from SciPy for more advanced mathematical operations that go beyond the basic capabilities of NumPy. For instance, tasks like optimization (e.g., scipy.optimize), sparse matrix computations, and some statistical functions are sourced from SciPy.\n",
    "Sparse Matrices: SciPy’s sparse matrix functionality is essential for handling large, sparse datasets in machine learning, which is particularly useful in tasks like natural language processing or large-scale data analysis.\n",
    "3. Scikit-learn\n",
    "Machine Learning Library: Scikit-learn is a high-level library built on top of NumPy and SciPy. It provides simple and efficient tools for data mining and data analysis, including implementations of various machine learning algorithms (e.g., classification, regression, clustering), preprocessing tools, model selection methods, and more.\n",
    "Interface with NumPy/SciPy: Scikit-learn uses NumPy arrays as inputs and outputs for its algorithms, making it seamless to integrate with other NumPy or SciPy-based code. For example, after preprocessing data with SciPy or performing numerical operations with NumPy, you can directly pass the processed data to a scikit-learn model.\n",
    "Dependency: Scikit-learn directly depends on both NumPy and SciPy, meaning it requires these libraries to be installed to function. This dependency ensures that scikit-learn can leverage the optimized performance and rich functionality of NumPy and SciPy.\n",
    "Summary:\n",
    "NumPy provides the basic array data structures and mathematical operations.\n",
    "SciPy builds on NumPy, offering more advanced mathematical tools and utilities.\n",
    "Scikit-learn builds on both NumPy and SciPy, providing high-level implementations of machine learning algorithms and data processing tools.\n",
    "\n",
    "\n",
    "Summary:\n",
    "\n",
    "NumPy provides the basic array data structures and mathematical operations.\n",
    "\n",
    "SciPy builds on NumPy, offering more advanced mathematical tools and utilities.\n",
    "\n",
    "Scikit-learn builds on both NumPy and SciPy, providing high-level implementations of machine learning algorithms and data processing tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1gavUMBXcHT"
   },
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg-lGodb8k7_"
   },
   "source": [
    "NumPy is one of the fundamental packages for scientific computing in Python. It contains functionality for multidimensional arrays, high-level mathematical functions such as linear algebra operations and the Fourier transform, and pseudorandom number generators.\n",
    "\n",
    "In scikit-learn, the NumPy array is the fundamental data structure. scikit-learn takes in data in the form of NumPy arrays. Any data you’re using will have to be converted to a NumPy array. \n",
    "\n",
    "Key features of NumPy include:\n",
    "\n",
    "1. **Arrays:** At the core of the NumPy package, is the **ndarray** object that encapsulates n-dimensional arrays of homogeneous data types. These arrays are more **efficient** than Python lists for numerical operations.\n",
    "\n",
    "2. **Indexing and Slicing:** NumPy provides powerful indexing and slicing capabilities for accessing and manipulating data within arrays. This makes it easy to extract subsets of data or modify specific elements.\n",
    "\n",
    "3. **Broadcasting:** NumPy allows for operations between arrays of different shapes and sizes through a mechanism called broadcasting. This makes it easy to perform element-wise operations on arrays of different shapes without the need for explicit looping or reshaping.\n",
    "\n",
    "4. **Parallelization:** NumPy operations can be parallelized, as they are often implemented using optimized low-level libraries that take advantage of parallel processing capabilities on modern hardware.\n",
    "\n",
    "NumPy is a foundational library in the Python data science ecosystem and is often used in conjunction with other libraries like Pandas, Matplotlib, and scikit-learn for tasks such as data manipulation, analysis, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvMLPVa3V_YA"
   },
   "source": [
    "### ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GIRS-b63V_YA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr_1d = np.array([1, 2, 3])\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "arr_3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg0vxMqzI7qn"
   },
   "source": [
    "Some key points about ndarray and its attributes:\n",
    "\n",
    "1. **Axis:**\n",
    "  - In NumPy, arrays can have one or more dimensions, and each dimension is referred to as an \"axis.\"\n",
    "\n",
    "  - Many NumPy functions allow operations to be performed along a specified axis. Common operations include ```sum, mean, minimum, maximum,``` etc. The axis parameter in these operations specify the direction along which an operation is applied. For example, when summing a 3D array along axis 0, the operation is performed along columns; when summing along axis 1, the operation is performed along rows.\n",
    "\n",
    "2. **Shape:**\n",
    "   - The \"shape\" of an ndarray refers to the size of the array. For example, a 1-dimensional array might have a shape like ```(5,)```, indicating it has 5 elements along a single axis. A 2-dimensional array might have a shape like ```(3, 4)```, indicating it has 3 rows and 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Aaeymv30Kf-y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of arr_1d: (3,)\n",
      "shape of arr_2d: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr_1d = np.array([1, 2, 3])\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"shape of arr_1d:\",arr_1d.shape)\n",
    "print(\"shape of arr_2d:\",arr_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfSvHc4sV_YC"
   },
   "source": [
    "### Data Types of ndarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNiM3d6qalvk"
   },
   "source": [
    "Understanding data types in NumPy is crucial as it allows us to control how data is stored in memory and how operations are performed on that data. NumPy provides a rich set of data types that are more efficient than the built-in Python types.\n",
    "\n",
    "Here are some key data types in NumPy:\n",
    "\n",
    "1. **int8, int16, int32, int64**: Signed integers with 8, 16, 32, or 64 bits of precision, respectively.\n",
    "\n",
    "2. **uint8, uint16, uint32, uint64**: Unsigned integers with 8, 16, 32, or 64 bits of precision, respectively.\n",
    "\n",
    "3. **float16, float32, float64**: Floating-point numbers with 16, 32, or 64 bits of precision, respectively.\n",
    "\n",
    "4. **complex64, complex128**: Complex numbers with 64 or 128 bits of precision, where the real and imaginary parts are represented by 32 or 64-bit floating-point numbers.\n",
    "\n",
    "5. **bool**: Boolean type storing True or False values.\n",
    "\n",
    "6. **object**: A generic object data type.\n",
    "\n",
    "7. **string_**: String data type.\n",
    "\n",
    "8. **unicode_**: Unicode data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zXG_VyI7D91"
   },
   "source": [
    "**You can specify the data type when creating a NumPy array using the `dtype` parameter.** For example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "# define the data type during array creation\n",
    "arr1 = np.array([1, 2, 3], dtype=np.int32)\n",
    "arr2 = np.array([1, 2, 3], dtype='int32')\n",
    "```\n",
    "You can change the data type of an array after it has been created using the `astype` function.\n",
    "```python\n",
    "import numpy as np\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "float_arr = arr.astype(np.float32)\n",
    "print(arr.dtype,float_arr.dtype)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy is a collection of functions for scientific computing in Python. It provides, among other functionality, advanced linear algebra routines, mathematical function optimization, signal processing, special mathematical functions, and statistical distributions. scikit-learn draws from SciPy’s collection of functions for implementing\n",
    "its algorithms.\n",
    "\n",
    "One of its key components is scipy.sparse, which provides efficient storage and manipulation of sparse matrices. Sparse matrices are matrices that are predominantly filled with zeros and contain very few non-zero elements.\n",
    "\n",
    "In many machine learning applications, especially when dealing with high-dimensional data (like text data in natural language processing), the data can be sparse. Using dense matrices (where all elements, including zeros, are stored in memory) for such data is often inefficient in terms of both memory and computational power. This is where sparse matrices come into play.\n",
    "\n",
    "\n",
    "scipy.sparse: provides sparse matrices, which are another representation that is used for data in scikitlearn.\n",
    "Sparse matrices are used whenever we want to store a 2D array that contains mostly zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "# Create a 2D NumPy array with a diagonal of ones, and zeros everywhere else (Creating a Dense Matrix (NumPy array))\n",
    "eye = np.eye(4)\n",
    "print(\"NumPy array:\\n{}\".format(eye))\n",
    "\n",
    "#np.eye(4) creates a 4x4 identity matrix, which is a square matrix with ones on the diagonal and zeros elsewhere.\n",
    "#This matrix is stored in a dense format, meaning every element (including the zeros) is explicitly stored in memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SciPy sparse CSR matrix:\n",
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Convert the NumPy array to a SciPy sparse matrix in Compressed Sparse Row (CSR) format\n",
    "# Only the nonzero entries are stored\n",
    "sparse_matrix = sparse.csr_matrix(eye)\n",
    "print(\"\\nSciPy sparse CSR matrix:\\n{}\".format(sparse_matrix))\n",
    "#The csr_matrix function from scipy.sparse converts the dense NumPy array into a sparse matrix using the Compressed Sparse Row (CSR) format.\n",
    "#In CSR format, only the non-zero elements are stored along with their row and column indices, making it much more memory-efficient for sparse data.\n",
    "#Instead of storing 16 elements, the CSR format stores only the 4 non-zero elements and their positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it is not possible to create dense representations of sparse data (as they would not fit into memory), so we need to create sparse representations directly. Here is a way to create the same sparse matrix as before, using the COO (Coordinate List) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COO representation:\n",
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "data = np.ones(4)\n",
    "row_indices = np.arange(4)\n",
    "col_indices = np.arange(4)\n",
    "eye_coo = sparse.coo_matrix((data, (row_indices, col_indices)))\n",
    "print(\"COO representation:\\n{}\".format(eye_coo))\n",
    "#Here, you're creating the sparse matrix directly using the Coordinate List (COO) format.\n",
    "#data contains the non-zero values (in this case, all ones).\n",
    "#row_indices and col_indices specify the row and column positions of each non-zero element.\n",
    "#coo_matrix constructs the sparse matrix from this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Use Sparse Matrices?\n",
    "\n",
    "Memory Efficiency: Sparse matrices save a significant amount of memory when dealing with large datasets that are mostly zeros. Instead of storing all the zeros, you only store the non-zero elements and their positions.\n",
    "\n",
    "Computational Efficiency: Operations on sparse matrices are often faster because the algorithms can skip over the zero elements, focusing only on the non-zero data.\n",
    "\n",
    "Use in Scikit-learn\n",
    "Scikit-learn leverages sparse matrices to handle large datasets efficiently, particularly in tasks like text classification where feature vectors can have thousands or even millions of dimensions, with most of them being zero. By using sparse matrices, scikit-learn can perform machine learning tasks without running into memory issues, making it possible to work with large-scale data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "INLD2p-49kie",
    "bTRfwHXZDewR",
    "cge2YGYM9pMA",
    "0WrEdRZV2icR",
    "r1gavUMBXcHT",
    "vvMLPVa3V_YA",
    "kfSvHc4sV_YC"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

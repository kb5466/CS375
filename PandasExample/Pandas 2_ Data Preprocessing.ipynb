{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v01JF_t15h5A"
   },
   "source": [
    "## Data Preprocessing\n",
    "Data preprocessing is a crucial step in the data analysis and machine learning pipeline. It involves the cleaning and transformation of raw data into a format that is suitable for analysis or input to a machine learning model. The main goals of data preprocessing are to improve the quality of the data and enhance the performance and effectiveness of machine learning models. The choice of preprocessing techniques is influenced by the nature of the data, and different algorithms are applied accordingly to address unique challenges associated with diverse data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVtxQgfIMt2g"
   },
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jiu5FFoiIjfx"
   },
   "source": [
    "The columns in a Pandas DataFrame can contain different types of data. Here are some common types you might encounter:\n",
    "\n",
    "1. **Numerical Data:**\n",
    "   - **Discrete:** These are numerical data that have a countable number of distinct values. For example, the **number of cars** in a parking lot or the **number of students in a classroom**.\n",
    "   - **Continuous :** They can take any numeric value within a range and have an infinite number of possible values. Examples include **height, weight, or temperature**.\n",
    "\n",
    "2. **Categorical Data:**\n",
    "   - **Nominal:** These type of data represent categories without any inherent order or ranking. Examples include **gender, color, or types of fruits**.\n",
    "   - **Ordinal:** They have categories with a meaningful order. Examples include socio economic status **(low income,middle income,high income), education level (high school,BS,MS,PhD)**.\n",
    "\n",
    "3. **Datetime :**\n",
    "   - **Datetime (datetime64):** Datetime data, also referred to as timestamp or time series data, represents information related to dates and times.\n",
    "\n",
    "4. **Sparse Data:**\n",
    "    - Sparse data refers to data where a large proportion of the elements have a value of zero. This type of data is common in various fields, such as natural language processing, recommendation systems, and network analysis. An example of sparse data is given below where rows represent users and columns represent movies. Each entry in the dataset indicates whether a user has rated a particular movie.\n",
    "\n",
    "    ```\n",
    "    User       Movie A   Movie B   Movie C   Movie D   Movie E\n",
    "    User 1        4         0         0         0         0\n",
    "    User 2        0         0         0         5         0\n",
    "    User 3        0         0         3         0         0\n",
    "    User 4        0         0         0         0         2\n",
    "    User 5        0         1         0         0         0\n",
    "    ```\n",
    "\n",
    "    - Sparse data often requires specific techniques and algorithms to efficiently handle and analyze, as processing all the zero values can be computationally expensive and may not provide meaningful insights.\n",
    "\n",
    "    - The `scipy.sparse` module provides a variety of sparse matrix types and operations for sparse matrix manipulations. It includes formats such as CSR (Compressed Sparse Row), CSC (Compressed Sparse Column), COO (Coordinate), and others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 2273,
     "status": "ok",
     "timestamp": 1726168520509,
     "user": {
      "displayName": "Yajuan LI",
      "userId": "07949580397633847884"
     },
     "user_tz": 240
    },
    "id": "H7yHJdX9T9x3",
    "outputId": "f932eb6d-881c-4b36-caf3-df773b02dfb5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 244,\n  \"fields\": [\n    {\n      \"column\": \"total_bill\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.95525411854967,\n        \"min\": 3.07,\n        \"max\": 50.81,\n        \"num_unique_values\": 226,\n        \"samples\": [\n          14.78,\n          7.56,\n          14.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tip\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3864939939817316,\n        \"min\": 1.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          4.08,\n          1.5,\n          6.73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Sat\",\n          \"Fri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Lunch\",\n          \"Dinner\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"two\",\n          \"three\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-c9764584-8a40-41d4-bcc0-49523fbb9ca7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9764584-8a40-41d4-bcc0-49523fbb9ca7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-c9764584-8a40-41d4-bcc0-49523fbb9ca7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-c9764584-8a40-41d4-bcc0-49523fbb9ca7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ce279637-ed60-4d3c-a272-9fd276b92b0e\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce279637-ed60-4d3c-a272-9fd276b92b0e')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ce279637-ed60-4d3c-a272-9fd276b92b0e button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time   size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner    two\n",
       "1       10.34  1.66    Male     No  Sun  Dinner  three\n",
       "2       21.01  3.50    Male     No  Sun  Dinner  three\n",
       "3       23.68  3.31    Male     No  Sun  Dinner    two\n",
       "4       24.59  3.61  Female     No  Sun  Dinner   four"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://drive.google.com/file/d/19aYZVyCsbKp0UEQl8QQagKyHFmromwQg/view?usp=sharing'\n",
    "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYkWEGcnfw-L"
   },
   "source": [
    "1. **total_bill (Numeric):** Represents the total bill amount for a meal, usually a float.\n",
    "\n",
    "2. **tip (Numeric):** Represents the tip amount given by the customer, usually a float.\n",
    "\n",
    "3. **sex (Categorical):** Represents the gender of the person paying the bill, often categorized as \"Male\" or \"Female.\"\n",
    "\n",
    "4. **smoker (Categorical):** Indicates whether the party was a smoker or non-smoker, often categorized as \"Yes\" or \"No.\"\n",
    "\n",
    "5. **day (Categorical):** Represents the day of the week when the meal took place, categorized as \"Thur,\" \"Fri,\" \"Sat,\" or \"Sun.\"\n",
    "\n",
    "6. **time (Categorical):** Indicates whether the meal was lunch or dinner.\n",
    "\n",
    "7. **size (Categorical):** Represents the size of the dining party.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4r4kMvleWkp-"
   },
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9hYyPAO64pf"
   },
   "source": [
    "Handling missing values is crucial in data science for several reasons:\n",
    "\n",
    "1. **Data Quality and Accuracy:** Missing values can introduce inaccuracies in the analysis, leading to incorrect conclusions. By addressing missing data, you improve the overall quality and accuracy of your dataset.\n",
    "\n",
    "2. **Statistical Power:** Missing data can reduce the statistical power of your analysis, making it challenging to draw meaningful conclusions. Proper handling of missing values ensures that your statistical tests are more robust and reliable.\n",
    "\n",
    "3. **Model Performance:** Many machine learning algorithms cannot handle missing values directly. Fitting models with missing data may lead to biased or inaccurate predictions.\n",
    "\n",
    "4. **Avoiding Biases:** If the missing data is not handled properly, it may introduce bias into the analysis. This bias can impact the generalizability of your findings and lead to incorrect interpretations.\n",
    "\n",
    "5. **Data Visualization:** Missing values can affect the visual representation of data, making it challenging to create accurate charts and graphs. Addressing missing data improves the clarity and reliability of data visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1726168639341,
     "user": {
      "displayName": "Yajuan LI",
      "userId": "07949580397633847884"
     },
     "user_tz": 240
    },
    "id": "2pXlaenfnVrv",
    "outputId": "e3f46541-f571-4862-b45c-491d44d7f9ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame with Missing Values:\n",
      "     Name   Age  Score           City\n",
      "0  Alice  25.0   85.0       New York\n",
      "1    Bob   NaN   92.0  San Francisco\n",
      "2    NaN  22.0    NaN    Los Angeles\n",
      "3  David  35.0   95.0            NaN\n",
      "4   Emma  28.0   89.0         Boston\n",
      "\n",
      "1. Detect missing values:\n",
      "     Name    Age  Score   City\n",
      "0  False  False  False  False\n",
      "1  False   True  False  False\n",
      "2   True  False   True  False\n",
      "3  False  False  False   True\n",
      "4  False  False  False  False\n",
      "\n",
      "Number of missing values in each column:\n",
      " Name     1\n",
      "Age      1\n",
      "Score    1\n",
      "City     1\n",
      "dtype: int64\n",
      "\n",
      "2. DataFrame after dropping rows with missing values:\n",
      "     Name   Age  Score      City\n",
      "0  Alice  25.0   85.0  New York\n",
      "4   Emma  28.0   89.0    Boston\n",
      "\n",
      "DataFrame after dropping columns with missing values:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n",
      "\n",
      "3. DataFrame after filling missing values with 0:\n",
      "     Name   Age  Score           City\n",
      "0  Alice  25.0   85.0       New York\n",
      "1    Bob   0.0   92.0  San Francisco\n",
      "2      0  22.0    0.0    Los Angeles\n",
      "3  David  35.0   95.0              0\n",
      "4   Emma  28.0   89.0         Boston\n",
      "\n",
      "DataFrame after filling missing values with the mean:\n",
      "     Name   Age  Score           City\n",
      "0  Alice  25.0  85.00       New York\n",
      "1    Bob  27.5  92.00  San Francisco\n",
      "2    NaN  22.0  90.25    Los Angeles\n",
      "3  David  35.0  95.00            NaN\n",
      "4   Emma  28.0  89.00         Boston\n",
      "\n",
      "4. DataFrame after interpolating missing values:\n",
      "     Name   Age  Score           City\n",
      "0  Alice  25.0   85.0       New York\n",
      "1    Bob  23.5   92.0  San Francisco\n",
      "2    NaN  22.0   93.5    Los Angeles\n",
      "3  David  35.0   95.0            NaN\n",
      "4   Emma  28.0   89.0         Boston\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-fd04a8cfecc2>:52: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df_interpolated = df.interpolate()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame  with missing values (you can also use the data in above cell)\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', np.nan, 'David', 'Emma'],\n",
    "    'Age': [25, np.nan, 22, 35, 28],\n",
    "    'Score': [85, 92, np.nan, 95, 89],\n",
    "    'City': ['New York', 'San Francisco', 'Los Angeles', np.nan, 'Boston']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Sample DataFrame with Missing Values:\\n\", df)\n",
    "# 1. Detecting Missing Data:\n",
    "# The isnull() method can be used to detect missing values in a DataFrame.\n",
    "# It returns a DataFrame of the same shape, where each element is True or False\n",
    "# based on whether the corresponding element in the original DataFrame is missing.\n",
    "missing_values = df.isnull()\n",
    "print(\"\\n1. Detect missing values:\\n\", missing_values)\n",
    "\n",
    "# Count the number of missing values in each column\n",
    "number_of_missing_values = df.isnull().sum()\n",
    "print(\"\\nNumber of missing values in each column:\\n\", number_of_missing_values)\n",
    "\n",
    "# 2. Dropping Missing Values:\n",
    "# The dropna() method can be used to remove rows or columns containing missing values.\n",
    "# The axis parameter specifies whether to drop rows (axis=0) or columns (axis=1).\n",
    "\n",
    "# Drop rows containing missing values\n",
    "df_no_missing_rows = df.dropna()\n",
    "print(\"\\n2. DataFrame after dropping rows with missing values:\\n\", df_no_missing_rows)\n",
    "\n",
    "# Drop columns containing missing values\n",
    "df_no_missing_cols = df.dropna(axis=1)\n",
    "print(\"\\nDataFrame after dropping columns with missing values:\\n\", df_no_missing_cols)\n",
    "\n",
    "# 3. Filling Missing Values:\n",
    "# The fillna() method can be used to fill missing values with a specific value or with the result of a function.\n",
    "\n",
    "# Fill missing values with a specific value (e.g., 0)\n",
    "df_filled = df.fillna(0)\n",
    "print(\"\\n3. DataFrame after filling missing values with 0:\\n\", df_filled)\n",
    "\n",
    "# Fill missing values with the mean of each numerical column, will fill NA for non-numerical column missing values\n",
    "df_mean_filled = df.fillna(df.mean(numeric_only=True))\n",
    "print(\"\\nDataFrame after filling missing values with the mean:\\n\", df_mean_filled)\n",
    "\n",
    "# 4. Interpolation:\n",
    "# The interpolate() method provides a way to perform linear interpolation to fill missing values based on the values around them.\n",
    "\n",
    "# Interpolate missing values\n",
    "df_interpolated = df.interpolate()\n",
    "print(\"\\n4. DataFrame after interpolating missing values:\\n\", df_interpolated)\n",
    "#for example: output shows row 1    Bob  23.5   92.0  San Francisco, here 23.5 comes from (25+22)/2, where 25 is from row 0, and 22 is from row 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcMkOxeaXI3f"
   },
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ux7pOK6gXZoq"
   },
   "source": [
    "Encoding, in the context of data science and machine learning, refers to the process of converting data from one form to another. It involves representing information in a different format, often to make it suitable for a specific purpose or to meet the requirements of a particular algorithm. Encoding is commonly used when dealing with categorical variables, text data, or other types of information that need to be transformed for analysis or modeling. It is a crucial step in the data preprocessing phase, especially when working with machine learning models.\n",
    "\n",
    "Most Common Categorical Data Encoding Techniques are:\n",
    "\n",
    "1. **Label Encoding:**\n",
    "\n",
    "    - Assigns a unique integer to each category.\n",
    "    - Suitable for ordinal data where there is a natural order among categories.\n",
    "    - Not recommended for nominal data as it may imply misleading relationships.\n",
    "\n",
    "2. **One-Hot Encoding:**\n",
    "\n",
    "    - Creates binary columns for each category (0 or 1).\n",
    "    - Suitable for nominal data without any natural order.\n",
    "    - Increases dimensionality but avoids false ordinal relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 182,
     "status": "ok",
     "timestamp": 1726171572135,
     "user": {
      "displayName": "Yajuan LI",
      "userId": "07949580397633847884"
     },
     "user_tz": 240
    },
    "id": "AkZPn9ypvGPP",
    "outputId": "4c9e0eac-69f2-4b89-a976-5e1641cf5bfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Ordinal):\n",
      "      Education\n",
      "0  High School\n",
      "1     Bachelor\n",
      "2       Master\n",
      "3          PhD\n",
      "4     Bachelor\n",
      "5       Master\n",
      "\n",
      "Label Encoded Data (Ordinal with Natural Order):\n",
      "      Education  Education_LabelEncoded\n",
      "0  High School                       1\n",
      "1     Bachelor                       0\n",
      "2       Master                       2\n",
      "3          PhD                       3\n",
      "4     Bachelor                       0\n",
      "5       Master                       2\n",
      "\n",
      "Label Encoded Data (Correct Order for Ordinal Data):\n",
      "      Education  Education_LabelEncoded\n",
      "0  High School                       0\n",
      "1     Bachelor                       1\n",
      "2       Master                       2\n",
      "3          PhD                       3\n",
      "4     Bachelor                       1\n",
      "5       Master                       2\n",
      "\n",
      "Original Data (Nominal):\n",
      "    Color\n",
      "0    Red\n",
      "1   Blue\n",
      "2  Green\n",
      "3   Blue\n",
      "4    Red\n",
      "5  Green\n",
      "\n",
      "One-Hot Encoded Data (Nominal without Natural Order) True/False:\n",
      "    Color_Blue  Color_Green  Color_Red\n",
      "0       False        False       True\n",
      "1        True        False      False\n",
      "2       False         True      False\n",
      "3        True        False      False\n",
      "4       False        False       True\n",
      "5       False         True      False\n",
      "\n",
      "One-Hot Encoded Data (Nominal without Natural Order) 0, 1:\n",
      "    Color_Blue  Color_Green  Color_Red\n",
      "0           0            0          1\n",
      "1           1            0          0\n",
      "2           0            1          0\n",
      "3           1            0          0\n",
      "4           0            0          1\n",
      "5           0            1          0\n",
      "\n",
      "One-Hot Encoded Data with drop_first=False:\n",
      "    Color_Green  Color_Red\n",
      "0            0          1\n",
      "1            0          0\n",
      "2            1          0\n",
      "3            0          0\n",
      "4            0          1\n",
      "5            1          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Example 1: Label Encoding for Natural Order Data\n",
    "# Natural order example: Education levels (Ordinal data)\n",
    "data_ordinal = {\n",
    "    'Education': ['High School', 'Bachelor', 'Master', 'PhD', 'Bachelor', 'Master']\n",
    "}\n",
    "\n",
    "df_ordinal = pd.DataFrame(data_ordinal)\n",
    "print(\"Original Data (Ordinal):\\n\", df_ordinal)\n",
    "\n",
    "# Label Encoding: Assigns unique integers to each category, reflecting the natural order\n",
    "# Here, we assume the order: High School < Bachelor < Master < PhD\n",
    "\n",
    "#                labels them based on alphabetical order if not specified\n",
    "label_encoder = LabelEncoder()\n",
    "df_ordinal['Education_LabelEncoded'] = label_encoder.fit_transform(df_ordinal['Education'])\n",
    "print(\"\\nLabel Encoded Data (Ordinal with Natural Order):\\n\", df_ordinal)\n",
    "\n",
    "#The issue with Label Encoding is that it doesn't inherently know the order of your categories; it assigns numbers based on the alphabetical order of the categories by default.\n",
    "#This means that the order \"High School < Bachelor < Master < PhD\" may not be preserved as expected. Instead, it sorts the categories alphabetically before assigning numbers.\n",
    "\n",
    "\n",
    "encoding_map = {'High School': 0, 'Bachelor': 1, 'Master': 2, 'PhD': 3}\n",
    "df_ordinal['Education_LabelEncoded'] = df_ordinal['Education'].map(encoding_map)\n",
    "\n",
    "print(\"\\nLabel Encoded Data (Correct Order for Ordinal Data):\\n\", df_ordinal)\n",
    "\n",
    "\n",
    "\n",
    "# Example 2: One-Hot Encoding for Nominal Data without Natural Order\n",
    "# Nominal data example: Colors (no natural order)\n",
    "data_nominal = {\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red', 'Green']\n",
    "}\n",
    "\n",
    "df_nominal = pd.DataFrame(data_nominal)\n",
    "print(\"\\nOriginal Data (Nominal):\\n\", df_nominal)\n",
    "\n",
    "# One-Hot Encoding: Creates binary columns for each category (0 or 1)\n",
    "one_hot_encoded = pd.get_dummies(df_nominal, columns=['Color'])\n",
    "#get_dummies() converts categorical variables into a series of binary (0 or 1) columns. Each column represents a unique category from the original column.\n",
    "print(\"\\nOne-Hot Encoded Data (Nominal without Natural Order) True/False:\\n\", one_hot_encoded)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(df_nominal, columns=['Color']).astype(int)\n",
    "print(\"\\nOne-Hot Encoded Data (Nominal without Natural Order) 0, 1:\\n\", one_hot_encoded)\n",
    "\n",
    "\n",
    "\n",
    "# Apply get_dummies with drop_first=False to keep all dummy variables\n",
    "\n",
    "#we drop the first row since we have 3, if on 2nd and 3rd are 0,0 then we know that the first row is is true\n",
    "one_hot_encoded_df = pd.get_dummies(df_nominal, columns=['Color'], drop_first=True).astype(int)\n",
    "print(\"\\nOne-Hot Encoded Data with drop_first=False:\\n\", one_hot_encoded_df)\n",
    "#drop_first=False (default): Keeps all the dummy variables, including one for each category.\n",
    "#drop_first=True: Drops the first category to avoid multicollinearity in cases where the encoded data will be used in regression models.\n",
    "#This approach is particularly useful when you need to reduce redundancy and avoid perfectly collinear variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIGYwtbq_dJO"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJG-hXAnAKHN"
   },
   "source": [
    "Feature scaling is a data preprocessing technique used to scale the values of features ( or attributes) in a dataset to a standard range. The primary goal of feature scaling is to ensure that all the features have similar scales, which can help improve the performance of many machine learning algorithms. It is particularly important when using algorithms that are sensitive to the scale of input features, such as gradient descent-based optimization methods (e.g., in neural networks) and distance-based algorithms (e.g., k-nearest neighbors or support vector machines).\n",
    "\n",
    "\n",
    "1. Min-Max Scaling (Normalization):\n",
    "   - Scales each feature to a given range (default is between 0 and 1).\n",
    "   - This is useful for normalizing features that need to fit within a bounded interval.\n",
    "   - The formula for min-max scaling is:\n",
    "     ```\n",
    "     X_normalized = (X - X_min) / (X_max - X_min)\n",
    "     ```\n",
    "   Here, X is the original feature value, X_normalized is the normalized value, X_min is the minimum value in the feature, and X_max is the maximum value in the feature.\n",
    "\n",
    "    **The function below accepts a Pandas series as a parameter and returns the scaled data:**\n",
    "    ```python\n",
    "    def minmax_scale(column):\n",
    "        min_val = column.min()\n",
    "        max_val = column.max()\n",
    "        scaled_column = (column - min_val) / (max_val - min_val)\n",
    "        return scaled_column\n",
    "    ```\n",
    "   \n",
    "\n",
    "2. Standardization:\n",
    "   - Also known as z-score standardization\n",
    "   - Scales features to have a mean of 0 and a standard deviation of 1.\n",
    "   - Commonly used when the data should follow a normal distribution for algorithms like SVMs and logistic regression.\n",
    "   - The formula for standardization is:\n",
    "     ```\n",
    "     X_standardized = (X - mean) / standard deviation\n",
    "     ```\n",
    "   - Here, X is the original feature value, X_standardized is the standardized value, mean is the mean of the feature values, and the standard deviation is the standard deviation of the feature values.\n",
    "   \n",
    "    **The function below accepts a Pandas series as a parameter and returns the scaled data:**\n",
    "   ```python\n",
    "    def zscore_standardize(column):\n",
    "        mean_val = column.mean()\n",
    "        std_dev = column.std()\n",
    "        standardized_column = (column - mean_val) / std_dev\n",
    "        return standardized_column\n",
    "   ```\n",
    "\n",
    "3. Robust Scaling:\n",
    "   - Scales features using statistics that are robust to outliers (median and IQR).The Interquartile Range (IQR) is a measure of statistical dispersion and is defined as the range between the first quartile (25th percentile, Q1) and the third quartile (75th percentile, Q3) of a dataset. IQR=Q3−Q1.\n",
    "   - Useful when data contains many outliers or is not normally distributed.\n",
    "   - The formula for robust scaling is:\n",
    "     ```\n",
    "     X_robust = (X - X_median) / (Q3 - Q1)\n",
    "     ```\n",
    "   Here, X is the original feature value, X_robust is the robust-scaled value, Q1 is the first quartile, and Q3 is the third quartile of the feature values.\n",
    "\n",
    "       **The function below accepts a Pandas series as a parameter and returns the scaled data:**\n",
    "\n",
    "      ```python\n",
    "      def robust_scale(column):\n",
    "        median_val = column.median()\n",
    "        iqr = column.quantile(0.75) - column.quantile(0.25)\n",
    "        scaled_column = (column - median_val) / iqr\n",
    "        return scaled_column\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1726171726782,
     "user": {
      "displayName": "Yajuan LI",
      "userId": "07949580397633847884"
     },
     "user_tz": 240
    },
    "id": "0_vVQjBy2jcE",
    "outputId": "9c89a829-7e89-45fa-db0d-1a0177f4fe59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    Feature1  Feature2  Feature3\n",
      "0       100         1        10\n",
      "1       150         2       100\n",
      "2       200         3      1000\n",
      "3       250         4     10000\n",
      "4       300         5    100000\n",
      "\n",
      "DataFrame with Scaled Features:\n",
      "    Feature1  Feature2  Feature3  Feature1_MinMax  Feature1_Standardized  \\\n",
      "0       100         1        10             0.00              -1.264911   \n",
      "1       150         2       100             0.25              -0.632456   \n",
      "2       200         3      1000             0.50               0.000000   \n",
      "3       250         4     10000             0.75               0.632456   \n",
      "4       300         5    100000             1.00               1.264911   \n",
      "\n",
      "   Feature1_Robust  Feature2_MinMax  Feature2_Standardized  Feature2_Robust  \\\n",
      "0             -1.0             0.00              -1.264911             -1.0   \n",
      "1             -0.5             0.25              -0.632456             -0.5   \n",
      "2              0.0             0.50               0.000000              0.0   \n",
      "3              0.5             0.75               0.632456              0.5   \n",
      "4              1.0             1.00               1.264911              1.0   \n",
      "\n",
      "   Feature3_MinMax  Feature3_Standardized  Feature3_Robust  \n",
      "0         0.000000              -0.508511        -0.100000  \n",
      "1         0.000900              -0.506451        -0.090909  \n",
      "2         0.009901              -0.485847         0.000000  \n",
      "3         0.099910              -0.279805         0.909091  \n",
      "4         1.000000               1.780614        10.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with some numeric data\n",
    "data = {\n",
    "    'Feature1': [100, 150, 200, 250, 300],\n",
    "    'Feature2': [1, 2, 3, 4, 5],\n",
    "    'Feature3': [10, 100, 1000, 10000, 100000]  # This column has a large range, showing how scaling affects it\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Min-Max Scaling Function\n",
    "def minmax_scale(column):\n",
    "    min_val = column.min()\n",
    "    max_val = column.max()\n",
    "    scaled_column = (column - min_val) / (max_val - min_val)\n",
    "    return scaled_column\n",
    "\n",
    "# Standardization (Z-score) Function\n",
    "def zscore_standardize(column):\n",
    "    mean_val = column.mean()\n",
    "    std_dev = column.std()\n",
    "    standardized_column = (column - mean_val) / std_dev\n",
    "    return standardized_column\n",
    "\n",
    "# Robust Scaling Function\n",
    "def robust_scale(column):\n",
    "    median_val = column.median()\n",
    "    iqr = column.quantile(0.75) - column.quantile(0.25)\n",
    "    scaled_column = (column - median_val) / iqr\n",
    "    return scaled_column\n",
    "\n",
    "# Applying the scaling functions to the DataFrame columns\n",
    "df['Feature1_MinMax'] = minmax_scale(df['Feature1'])\n",
    "df['Feature1_Standardized'] = zscore_standardize(df['Feature1'])\n",
    "df['Feature1_Robust'] = robust_scale(df['Feature1'])\n",
    "\n",
    "df['Feature2_MinMax'] = minmax_scale(df['Feature2'])\n",
    "df['Feature2_Standardized'] = zscore_standardize(df['Feature2'])\n",
    "df['Feature2_Robust'] = robust_scale(df['Feature2'])\n",
    "\n",
    "df['Feature3_MinMax'] = minmax_scale(df['Feature3'])\n",
    "df['Feature3_Standardized'] = zscore_standardize(df['Feature3'])\n",
    "df['Feature3_Robust'] = robust_scale(df['Feature3'])\n",
    "\n",
    "# Display the DataFrame with scaled features\n",
    "print(\"\\n DataFrame with Scaled Features:\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYpfJGYR6TjH"
   },
   "source": [
    "Instead of manually implementing feature scaling functions, we can use built-in functions from libraries like scikit-learn, which provides efficient and easy-to-use scaling functions for Min-Max Scaling, Standardization, and Robust Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1726172015955,
     "user": {
      "displayName": "Yajuan LI",
      "userId": "07949580397633847884"
     },
     "user_tz": 240
    },
    "id": "phD2wN7C3mKu",
    "outputId": "7ad9a15f-e8da-4ec4-fe1d-94507bc2d2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    Feature1  Feature2  Feature3\n",
      "0       100         1        10\n",
      "1       150         2       100\n",
      "2       200         3      1000\n",
      "3       250         4     10000\n",
      "4       300         5    100000\n",
      "\n",
      "DataFrame with Scaled Features:\n",
      "    Feature1  Feature2  Feature3  Feature1_MinMax  Feature2_MinMax  \\\n",
      "0       100         1        10             0.00             0.00   \n",
      "1       150         2       100             0.25             0.25   \n",
      "2       200         3      1000             0.50             0.50   \n",
      "3       250         4     10000             0.75             0.75   \n",
      "4       300         5    100000             1.00             1.00   \n",
      "\n",
      "   Feature3_MinMax  Feature1_Standardized  Feature2_Standardized  \\\n",
      "0         0.000000              -1.414214              -1.414214   \n",
      "1         0.000900              -0.707107              -0.707107   \n",
      "2         0.009901               0.000000               0.000000   \n",
      "3         0.099910               0.707107               0.707107   \n",
      "4         1.000000               1.414214               1.414214   \n",
      "\n",
      "   Feature3_Standardized  Feature1_Robust  Feature2_Robust  Feature3_Robust  \n",
      "0              -0.568533             -1.0             -1.0        -0.100000  \n",
      "1              -0.566229             -0.5             -0.5        -0.090909  \n",
      "2              -0.543193              0.0              0.0         0.000000  \n",
      "3              -0.312831              0.5              0.5         0.909091  \n",
      "4               1.990787              1.0              1.0        10.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# Sample DataFrame  with some numeric data\n",
    "data = {\n",
    "    'Feature1': [100, 150, 200, 250, 300],\n",
    "    'Feature2': [1, 2, 3, 4, 5],\n",
    "    'Feature3': [10, 100, 1000, 10000, 100000]  # This column has a large range, showing how scaling affects it\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "\n",
    "# Initializing the scalers\n",
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Applying Min-Max Scaling\n",
    "df_minmax_scaled = pd.DataFrame(minmax_scaler.fit_transform(df), columns=df.columns)\n",
    "df_minmax_scaled.columns = [f\"{col}_MinMax\" for col in df_minmax_scaled.columns]\n",
    "\n",
    "# Applying Standardization (Z-score Scaling)\n",
    "df_standard_scaled = pd.DataFrame(standard_scaler.fit_transform(df), columns=df.columns)\n",
    "df_standard_scaled.columns = [f\"{col}_Standardized\" for col in df_standard_scaled.columns]\n",
    "\n",
    "# Applying Robust Scaling\n",
    "df_robust_scaled = pd.DataFrame(robust_scaler.fit_transform(df), columns=df.columns)\n",
    "df_robust_scaled.columns = [f\"{col}_Robust\" for col in df_robust_scaled.columns]\n",
    "\n",
    "# Concatenating the results into one DataFrame for comparison\n",
    "df_scaled = pd.concat([df, df_minmax_scaled, df_standard_scaled, df_robust_scaled], axis=1)\n",
    "\n",
    "# Display the DataFrame with scaled features\n",
    "print(\"\\nDataFrame with Scaled Features:\\n\", df_scaled)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aVtxQgfIMt2g",
    "qcMkOxeaXI3f",
    "ep_j4HXrsM8C",
    "75ipY4SVtEDh"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
